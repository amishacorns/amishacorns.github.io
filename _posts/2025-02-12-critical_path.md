---
title: 'All Paths Lead to AGI'
date: 2025-02-12
permalink: /posts/paths/
tags:
  - artificial intelligence
  - research
---


You are a research advisor who coordinates all government, academic, and industrial research labs. You have near limitless funding and you need to allocate it across society to improve outcomes as best as possible. You can determine the research direction for every scientist, in every country, and in every discipline. What would be the best allocation of personnel and capital across disciplines? In the past, this question was difficult since progress was needed in all fields at the same time, and their progress was relatively siloed. You need to improve medicine, concrete for roads, steel for buildings, and so on, and you would need to weigh the importance of each and allocate in proportion. There of course were often joint bursts that applied to every field like the discovery of calculus, invention of computers, etc., but overall each field progressed relatively slowly in mostly isolated communities.


## Modern Allocation


AGI will be the final and largest joint burst across disciplines, and for that reason, this question of optimal allocation is no longer difficult. As we get sufficiently close to this AGI transition, the gradients across disciplines (which point in the direction of maximum progress) begin to align. For every discipline, its path of fastest progress leads through AI, since the incremental progress made in the period before and during the transition is nearly negligible compared to the progress after the transition. That is, if you quicken the onset of super-intelligence by 1.4% by reallocating the majority of funding of cancer research to AI in the short-term, on a three-year horizon you may slow its progress. Yet, on a ten-year horizon, you increase the progress by possibly 5x. This is true in all fields at the same time today, where their progress is inconsequential to the post-AGI progress. This has a sort of sad but simple conclusion. If your goal is to cure cancer, you should contribute to the development of AI, not biology or oncology. If you want to solve the remaining Millenium Prize problems, you should advance AI and not mathematics. If you want to advance the understanding of Sumerian Mythology, you should work to improve AI. Or early Islamic literature, Javanese phonology, room temperature superconductors, quantum computing, or the physics of black holes.


![Arbitrary Trajectories](/images/critical.png){: style="display: block; margin: 0 auto;"}


This means that over a time-horizon that spans the AGI transition, the critical path for progress in every field passes through the current development of AI. The figure above shows a toy example of this for different disciplines, where the thick line is the trajectory with the addition of AGI and thin is the continued trajectory without it. It shows roughly two cases, fields like cancer research which are still making steady but slow progress and fields like mathematics which may be approaching human-level saturation. In the saturated cases, AGI will clearly be necessary to jump-start progress. Yet, even for cancer research, the more resources you take away and reallocate to AGI, the faster its progress over reasonable timescales. This is because applying $100M to slightly left-shift the AGI transition (comically represented as discrete in the figure) will increase the progress faster than applying these resources through traditional medical institutions and universities.

This does not suggest that everyone should become research scientists or machine learning engineers, since even if that were possible, the benefits from more people in these positions saturates very quickly. But, the majority of global focus should begin to support the development and deployment of safe AGI. This involves moving toward generating larger human-driven datasets, training on integration of AI into all fields, more regulation on methods and compute to ensure successful deployment of AI, manual reviewing of AI reasoning traces or building methods for doing so. Also the AGI-transition will last a very long time and decisions will still need to be made on what degree of control will be given to AI in each field. With that in mind, we still need many domain-experts to oversee the AI systems.This is the most difficult transition that any civilization attempts to make, and it needs the full focus and involvement from as many people as possible.
